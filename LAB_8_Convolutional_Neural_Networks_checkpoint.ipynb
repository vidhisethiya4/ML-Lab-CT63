{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "LAB_8_Convolutional_Neural_Networks-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHDWb8jzkqI3"
      },
      "source": [
        "# Part 1: Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAxVZg8kqI6"
      },
      "source": [
        "###  Importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSTapDRkqI9"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "from keras.models import Model\n",
        "import timeit\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "3otQrU4JWLej"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEKUqkgGkqJI"
      },
      "source": [
        "### Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtwFbXyskqJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd612e8d-9fa8-40ee-d751-7c7876dc1f6e"
      },
      "source": [
        "batch_size = 70\n",
        "num_classes = 10\n",
        "epochs = 45\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test =to_categorical(y_test, num_classes)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2A1KfUskqJT"
      },
      "source": [
        "### Building a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMtSvqMdkqJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee188a7-8cc7-4104-9877-578b8e3c797d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(86, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 8)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 86)                34486     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 86)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                870       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,604\n",
            "Trainable params: 36,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Aab-hxdkqJc"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MWvDXQgkqJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7532cbca-dd11-4fc1-e007-0bb5aace5105"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.4962 - accuracy: 0.8428 - val_loss: 0.1096 - val_accuracy: 0.9657\n",
            "Epoch 2/45\n",
            "858/858 [==============================] - 18s 21ms/step - loss: 0.2062 - accuracy: 0.9376 - val_loss: 0.0766 - val_accuracy: 0.9754\n",
            "Epoch 3/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.1611 - accuracy: 0.9506 - val_loss: 0.0618 - val_accuracy: 0.9799\n",
            "Epoch 4/45\n",
            "858/858 [==============================] - 18s 22ms/step - loss: 0.1358 - accuracy: 0.9593 - val_loss: 0.0513 - val_accuracy: 0.9829\n",
            "Epoch 5/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.1223 - accuracy: 0.9638 - val_loss: 0.0476 - val_accuracy: 0.9843\n",
            "Epoch 6/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.1122 - accuracy: 0.9667 - val_loss: 0.0431 - val_accuracy: 0.9856\n",
            "Epoch 7/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.1038 - accuracy: 0.9688 - val_loss: 0.0429 - val_accuracy: 0.9857\n",
            "Epoch 8/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0976 - accuracy: 0.9700 - val_loss: 0.0369 - val_accuracy: 0.9879\n",
            "Epoch 9/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0942 - accuracy: 0.9720 - val_loss: 0.0364 - val_accuracy: 0.9875\n",
            "Epoch 10/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0866 - accuracy: 0.9741 - val_loss: 0.0331 - val_accuracy: 0.9892\n",
            "Epoch 11/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0822 - accuracy: 0.9748 - val_loss: 0.0330 - val_accuracy: 0.9884\n",
            "Epoch 12/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0834 - accuracy: 0.9742 - val_loss: 0.0313 - val_accuracy: 0.9892\n",
            "Epoch 13/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0786 - accuracy: 0.9763 - val_loss: 0.0316 - val_accuracy: 0.9893\n",
            "Epoch 14/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0762 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9896\n",
            "Epoch 15/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0749 - accuracy: 0.9778 - val_loss: 0.0283 - val_accuracy: 0.9909\n",
            "Epoch 16/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0716 - accuracy: 0.9783 - val_loss: 0.0336 - val_accuracy: 0.9892\n",
            "Epoch 17/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 0.0308 - val_accuracy: 0.9896\n",
            "Epoch 18/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.0293 - val_accuracy: 0.9904\n",
            "Epoch 19/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0648 - accuracy: 0.9802 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
            "Epoch 20/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0649 - accuracy: 0.9796 - val_loss: 0.0304 - val_accuracy: 0.9905\n",
            "Epoch 21/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0636 - accuracy: 0.9801 - val_loss: 0.0308 - val_accuracy: 0.9895\n",
            "Epoch 22/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0289 - val_accuracy: 0.9905\n",
            "Epoch 23/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0614 - accuracy: 0.9809 - val_loss: 0.0278 - val_accuracy: 0.9916\n",
            "Epoch 24/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0619 - accuracy: 0.9812 - val_loss: 0.0265 - val_accuracy: 0.9911\n",
            "Epoch 25/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0633 - accuracy: 0.9813 - val_loss: 0.0286 - val_accuracy: 0.9907\n",
            "Epoch 26/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0593 - accuracy: 0.9812 - val_loss: 0.0265 - val_accuracy: 0.9910\n",
            "Epoch 27/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0600 - accuracy: 0.9816 - val_loss: 0.0265 - val_accuracy: 0.9913\n",
            "Epoch 28/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0580 - accuracy: 0.9821 - val_loss: 0.0253 - val_accuracy: 0.9920\n",
            "Epoch 29/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0264 - val_accuracy: 0.9913\n",
            "Epoch 30/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0552 - accuracy: 0.9826 - val_loss: 0.0254 - val_accuracy: 0.9918\n",
            "Epoch 31/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0263 - val_accuracy: 0.9916\n",
            "Epoch 32/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0260 - val_accuracy: 0.9913\n",
            "Epoch 33/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0544 - accuracy: 0.9829 - val_loss: 0.0276 - val_accuracy: 0.9911\n",
            "Epoch 34/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.0268 - val_accuracy: 0.9917\n",
            "Epoch 35/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 0.0279 - val_accuracy: 0.9910\n",
            "Epoch 36/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.0264 - val_accuracy: 0.9916\n",
            "Epoch 37/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0511 - accuracy: 0.9842 - val_loss: 0.0333 - val_accuracy: 0.9904\n",
            "Epoch 38/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
            "Epoch 39/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0523 - accuracy: 0.9834 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
            "Epoch 40/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0509 - accuracy: 0.9840 - val_loss: 0.0264 - val_accuracy: 0.9912\n",
            "Epoch 41/45\n",
            "858/858 [==============================] - 19s 23ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 0.0268 - val_accuracy: 0.9911\n",
            "Epoch 42/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0491 - accuracy: 0.9847 - val_loss: 0.0272 - val_accuracy: 0.9910\n",
            "Epoch 43/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0508 - accuracy: 0.9841 - val_loss: 0.0247 - val_accuracy: 0.9920\n",
            "Epoch 44/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0278 - val_accuracy: 0.9909\n",
            "Epoch 45/45\n",
            "858/858 [==============================] - 19s 22ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 0.0248 - val_accuracy: 0.9921\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac38fb6090>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gprccy28kqJn"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74OuyWUkkqJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36775af1-4e29-4836-b52d-3e44a6e87ae5"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.02481720969080925\n",
            "Test accuracy: 0.9921000003814697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMO1hxHkqJw"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHv0D_xhkqJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "91b0b5d9-a61f-44ab-a006-0964d73ece7d"
      },
      "source": [
        "import pylab as plt\n",
        "\n",
        "plt.imshow(x_test[122].reshape(28,28),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "li=[0.5, 0,0.4, 0,0,0]\n",
        "li=np.array(li)\n",
        "thresholded = (li>=0.5)*1\n",
        "thresholded "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFYYp7JEaHoj",
        "outputId": "363fb4c2-905e-463d-fb6d-55d4ffe96b27"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7ffffzwBkqJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1e77ae-4ba5-418d-e57f-f319ed9b643f"
      },
      "source": [
        "import numpy as np\n",
        "prediction = model.predict(x_test[122:123])\n",
        "print('Prediction Score:\\n',prediction[0])\n",
        "thresholded = (prediction>0.5)*1\n",
        "print('\\nThresholded Score:\\n',thresholded[0])\n",
        "print('\\nPredicted Digit:\\n',np.where(thresholded == 1)[1])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Score:\n",
            " [9.6952273e-12 1.7764554e-06 4.5855142e-08 9.6874055e-07 9.4314589e-10\n",
            " 1.1547798e-09 9.3692711e-15 9.9999714e-01 1.3596720e-09 9.3886783e-08]\n",
            "\n",
            "Thresholded Score:\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            "\n",
            "Predicted Digit:\n",
            " [7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKT5OJSVkqJ8"
      },
      "source": [
        "# Part 2: Applications of Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzUY5QxykqJ_"
      },
      "source": [
        "###  MobileNet Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVPVmwIZkqKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f1bdfe-eb73-416d-fc00-d489f818b26d"
      },
      "source": [
        "model = MobileNet(input_shape=None, alpha=0.25, depth_multiplier=1, dropout=1e-3, \n",
        "                                 include_top=True, weights='imagenet', input_tensor=None, pooling=None, classes=1000)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenet_0.25_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv1 (Conv2D)              (None, 112, 112, 8)       216       \n",
            "                                                                 \n",
            " conv1_bn (BatchNormalizatio  (None, 112, 112, 8)      32        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv1_relu (ReLU)           (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 8)      72        \n",
            "                                                                 \n",
            " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 8)      32        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_1_relu (ReLU)       (None, 112, 112, 8)       0         \n",
            "                                                                 \n",
            " conv_pw_1 (Conv2D)          (None, 112, 112, 16)      128       \n",
            "                                                                 \n",
            " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 16)     64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_1_relu (ReLU)       (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 16)      0         \n",
            "                                                                 \n",
            " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 16)       144       \n",
            "                                                                 \n",
            " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 16)       64        \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_2_relu (ReLU)       (None, 56, 56, 16)        0         \n",
            "                                                                 \n",
            " conv_pw_2 (Conv2D)          (None, 56, 56, 32)        512       \n",
            "                                                                 \n",
            " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_2_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_3 (Conv2D)          (None, 56, 56, 32)        1024      \n",
            "                                                                 \n",
            " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_3_relu (ReLU)       (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 32)        0         \n",
            "                                                                 \n",
            " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 32)       288       \n",
            "                                                                 \n",
            " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 32)       128       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_4_relu (ReLU)       (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " conv_pw_4 (Conv2D)          (None, 28, 28, 64)        2048      \n",
            "                                                                 \n",
            " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_4_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_5 (Conv2D)          (None, 28, 28, 64)        4096      \n",
            "                                                                 \n",
            " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_5_relu (ReLU)       (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 64)       576       \n",
            "                                                                 \n",
            " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 64)       256       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_6_relu (ReLU)       (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv_pw_6 (Conv2D)          (None, 14, 14, 128)       8192      \n",
            "                                                                 \n",
            " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_6_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_7 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_7_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_8 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_8_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 128)      1152      \n",
            "                                                                 \n",
            " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_dw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_9 (Conv2D)          (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 128)      512       \n",
            " ation)                                                          \n",
            "                                                                 \n",
            " conv_pw_9_relu (ReLU)       (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_10 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_10_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_10_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 128)      1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pw_11 (Conv2D)         (None, 14, 14, 128)       16384     \n",
            "                                                                 \n",
            " conv_pw_11_bn (BatchNormali  (None, 14, 14, 128)      512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_11_relu (ReLU)      (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 128)      0         \n",
            "                                                                 \n",
            " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 128)        1152      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_12_bn (BatchNormali  (None, 7, 7, 128)        512       \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_12_relu (ReLU)      (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv_pw_12 (Conv2D)         (None, 7, 7, 256)         32768     \n",
            "                                                                 \n",
            " conv_pw_12_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_12_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 256)        2304      \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv_dw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_dw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv_pw_13 (Conv2D)         (None, 7, 7, 256)         65536     \n",
            "                                                                 \n",
            " conv_pw_13_bn (BatchNormali  (None, 7, 7, 256)        1024      \n",
            " zation)                                                         \n",
            "                                                                 \n",
            " conv_pw_13_relu (ReLU)      (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 1, 1, 256)        0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 256)         0         \n",
            "                                                                 \n",
            " conv_preds (Conv2D)         (None, 1, 1, 1000)        257000    \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 1000)              0         \n",
            "                                                                 \n",
            " predictions (Activation)    (None, 1000)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 475,544\n",
            "Trainable params: 470,072\n",
            "Non-trainable params: 5,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaGjhRRmkqKI"
      },
      "source": [
        "###  Classify images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTFWBD9FkqKK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "537ba361-132c-4586-fefb-857a13b5d602"
      },
      "source": [
        "# Write the image name below\n",
        "\n",
        "img_path = '.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "print('Predicted:\\n', decode_predictions(preds))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-04fcfc3eed96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \"\"\"\n\u001b[1;32m    313\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 314\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvvQWG_8kqKQ"
      },
      "source": [
        "###  Extract CNN features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rT0iPnxkqKS"
      },
      "source": [
        "features = model.predict(x)\n",
        "print('\\nFeature Shape:\\n',features.shape)\n",
        "print('\\nFeatures:\\n',features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYHHR_bskqKY"
      },
      "source": [
        "###  Extract features from an arbitrary intermediate layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOrIUA2DkqKb"
      },
      "source": [
        "model_minimal = Model(input=model.input, output=model.get_layer('conv_dw_2_relu').output)\n",
        "\n",
        "conv_dw_2_relu_features = model_minimal.predict(x)\n",
        "print('Features of conv_dw_2_relu:',conv_dw_2_relu_features.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oPYajJZkqKh"
      },
      "source": [
        "### You can extract these features and use the base network as a feature extractor for your problems. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5z5cFn5kqKj"
      },
      "source": [
        "# Part 3: Deep Convolution Layer Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjr6DcimkqKm"
      },
      "source": [
        "import matplotlib as mp\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOMgk22xkqKr"
      },
      "source": [
        "### Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6PBNav6kqKt"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-nifFGhkqKy"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9LkN_paDkqKz"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None, 784],name=\"x-in\")\n",
        "true_y = tf.placeholder(tf.float32, [None, 10],name=\"y-in\")\n",
        "keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "x_image = tf.reshape(x,[-1,28,28,1])\n",
        "hidden_1 = slim.conv2d(x_image,5,[5,5])\n",
        "pool_1 = slim.max_pool2d(hidden_1,[2,2])\n",
        "hidden_2 = slim.conv2d(pool_1,5,[5,5])\n",
        "pool_2 = slim.max_pool2d(hidden_2,[2,2])\n",
        "hidden_3 = slim.conv2d(pool_2,20,[5,5])\n",
        "hidden_3 = slim.dropout(hidden_3,keep_prob)\n",
        "out_y = slim.fully_connected(slim.flatten(hidden_3),10,activation_fn=tf.nn.softmax)\n",
        "\n",
        "cross_entropy = -tf.reduce_sum(true_y*tf.log(out_y))\n",
        "correct_prediction = tf.equal(tf.argmax(out_y,1), tf.argmax(true_y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEodGsOUkqK5"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UPBduFekqK6"
      },
      "source": [
        "batchSize = 50\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "for i in range(1001):\n",
        "    batch = mnist.train.next_batch(batchSize)\n",
        "    sess.run(train_step, feed_dict={x:batch[0],true_y:batch[1], keep_prob:0.5})\n",
        "    if i % 100 == 0 and i != 0:\n",
        "        trainAccuracy = sess.run(accuracy, feed_dict={x:batch[0],true_y:batch[1], keep_prob:1.0})\n",
        "        print(\"step %d, training accuracy %g\"%(i, trainAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OTeqbaJkqLA"
      },
      "source": [
        "### Testing accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-JBoLBAkqLB"
      },
      "source": [
        "testAccuracy = sess.run(accuracy, feed_dict={x:mnist.test.images,true_y:mnist.test.labels, keep_prob:1.0})\n",
        "print(\"test accuracy %g\"%(testAccuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2BhkZBskqLI"
      },
      "source": [
        "### Get activation values and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8DOheo-hkqLJ"
      },
      "source": [
        "def getActivations(layer,stimuli):\n",
        "    units = sess.run(layer,feed_dict={x:np.reshape(stimuli,[1,784],order='F'),keep_prob:1.0})\n",
        "    plotNNFilter(units)\n",
        "    \n",
        "def plotNNFilter(units):\n",
        "    filters = units.shape[3]\n",
        "    plt.figure(1, figsize=(20,20))\n",
        "    n_columns = 6\n",
        "    n_rows = math.ceil(filters / n_columns) + 1\n",
        "    for i in range(filters):\n",
        "        plt.subplot(n_rows, n_columns, i+1)\n",
        "        plt.title('Filter ' + str(i))\n",
        "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkoaARCnkqLO"
      },
      "source": [
        "### Input Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdOll7bkqLQ"
      },
      "source": [
        "imageToUse = mnist.test.images[0]\n",
        "plt.imshow(np.reshape(imageToUse,[28,28]), interpolation=\"nearest\", cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZ5UZDkkqLV"
      },
      "source": [
        "### Activation in Layer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5dxXfvPkqLX"
      },
      "source": [
        "getActivations(hidden_1,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9gNAvrkqLd"
      },
      "source": [
        "### Activation in Layer 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlb3LGrWkqLe"
      },
      "source": [
        "getActivations(hidden_2,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhqGvOEkkqLl"
      },
      "source": [
        "### Activation in Layer 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmkgnW5ckqLo"
      },
      "source": [
        "getActivations(hidden_3,imageToUse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0awq5VogkqLt"
      },
      "source": [
        "# Part 4: Design Choices in Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGnsygzkqLv"
      },
      "source": [
        "## Influence of convolution size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWVCTsJPkqLy"
      },
      "source": [
        "### Model with (3 x 3) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5wWkLbAkqL0"
      },
      "source": [
        "K.clear_session()\n",
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAuW0NOHkqL7"
      },
      "source": [
        "### Model with (7 x 7) Convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnphlXbvkqL8"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by2WASoQkqMD"
      },
      "source": [
        "## Striding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h9XyTZKkqME"
      },
      "source": [
        "### Model with (7 x 7) Convolution with 2 Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K39I1weskqMF"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=2, activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=2, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz6_wR8GkqMK"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kln95ykqMM"
      },
      "source": [
        "### Model with (7 x 7) Convolution with Same Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QinhffvkkqMO"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(7, 7), strides=1, padding='same', activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(16, (7, 7), strides=1, padding='same', activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLPfWDdYkqMT"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhAfYO0kqMV"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (2 x 2) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMSL5flZkqMW"
      },
      "source": [
        "start = timeit.default_timer()   \n",
        "model = Sequential()\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "end = timeit.default_timer()\n",
        "print(\"Time Taken to run the model:\",end - start, \"seconds\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHtxt0kqMc"
      },
      "source": [
        "### Model with (3 x 3) Convolution with Pooling (3 x 3) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w9kCVL7kqMe"
      },
      "source": [
        "# Write your code here \n",
        "\n",
        "# Use the same model design from the above cell "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzV7LwepkqMn"
      },
      "source": [
        "### What are your findings?"
      ]
    }
  ]
}